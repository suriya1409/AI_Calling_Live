"""
AI Calling Service - User Isolation & Standalone Models Integrated
==================
Core service for handling AI-powered phone calls using Vonage, Sarvam AI, and Gemini
"""

import os
import json
import base64
import uuid
import time
import jwt
import wave
import struct
import threading
from io import BytesIO
from datetime import datetime
from queue import Queue
import re
import random
import asyncio

import requests
from vonage import Vonage, Auth

# Import Gemini SDK
try:
    from google import genai
    from google.genai import types
    GEMINI_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è  WARNING: google-genai not installed. Install with: pip install google-genai")
    GEMINI_AVAILABLE = False

try:
    from groq import Groq
    GROQ_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è  WARNING: groq not installed. Install with: pip install groq")
    GROQ_AVAILABLE = False

# Configure logging
import logging
logger = logging.getLogger(__name__)

# Import standalone model functions
from app.table_models.call_sessions import create_call_session
from app.table_models.borrowers_table import update_borrower

# ============================================================
# GLOBAL STORAGE
# ============================================================

call_data = {}
audio_cache = {}

# Initialize Vonage client
try:
    # Use private key content string if available (for Render), otherwise fallback to file path
    p_key = settings.VONAGE_PRIVATE_KEY if settings.VONAGE_PRIVATE_KEY else settings.VONAGE_PRIVATE_KEY_PATH
    
    vonage_client = Vonage(Auth(
        application_id=settings.VONAGE_APPLICATION_ID,
        private_key=p_key
    ))
    voice = vonage_client.voice
    logger.info("[VONAGE] ‚úÖ Vonage Voice client initialized")
except Exception as e:
    logger.error(f"[VONAGE] ‚ö†Ô∏è  Failed to initialize: {e}")
    vonage_client = None
    voice = None

# Initialize Gemini AI client
gemini_client = None
if GEMINI_AVAILABLE and settings.GEMINI_API_KEY:
    try:
        gemini_client = genai.Client(api_key=settings.GEMINI_API_KEY)
        logger.info("[GEMINI] ‚úÖ Gemini AI client initialized")
    except Exception as e:
        logger.error(f"[GEMINI] ‚ö†Ô∏è  Failed to initialize: {e}")
        gemini_client = None
else:
    logger.warning("[GEMINI] ‚ö†Ô∏è  Gemini not configured - AI analysis will be disabled")

# Initialize Groq AI client
groq_client = None
print(f"[DEBUG] GROQ_AVAILABLE: {GROQ_AVAILABLE}")
print(f"[DEBUG] settings.GROQ_API_KEY present: {bool(settings.GROQ_API_KEY)}")

if GROQ_AVAILABLE and settings.GROQ_API_KEY:
    if "your_groq_api_key_here" in settings.GROQ_API_KEY:
        logger.warning("[GROQ] ‚ö†Ô∏è  Groq API key is still the placeholder. Please update .env")
    else:
        try:
            from groq import AsyncGroq
            groq_client = AsyncGroq(api_key=settings.GROQ_API_KEY)
            logger.info("[GROQ] ‚úÖ Async Groq AI client initialized")
        except Exception as e:
            logger.error(f"[GROQ] ‚ö†Ô∏è  Failed to initialize: {e}")
            groq_client = None
else:
    if not GROQ_AVAILABLE:
        print("[GROQ] ‚ö†Ô∏è  Groq library not installed.")
    if not settings.GROQ_API_KEY:
        print("[GROQ] ‚ö†Ô∏è  GROQ_API_KEY not found in settings.")
    print("[GROQ] ‚ö†Ô∏è  Groq not configured - fallback analysis will be disabled")

# Initialize SYNC Groq client (for real-time responses in Flask sync context)
sync_groq_client = None
if GROQ_AVAILABLE and settings.GROQ_API_KEY and "your_groq_api_key_here" not in settings.GROQ_API_KEY:
    try:
        sync_groq_client = Groq(api_key=settings.GROQ_API_KEY)
        print("[GROQ] ‚úÖ Sync Groq client initialized for real-time call responses")
    except Exception as e:
        print(f"[GROQ] ‚ö†Ô∏è  Failed to initialize sync client: {e}")
        sync_groq_client = None


# ============================================================
# HELPER FUNCTIONS
# ============================================================

# Common Indian female first names for gender detection
_FEMALE_NAMES = {
    "shalini", "priya", "lakshmi", "deepa", "anita", "sunita", "kavita", "meena",
    "rekha", "neha", "pooja", "swati", "anjali", "divya", "sneha", "ritu",
    "nisha", "rani", "geeta", "seema", "mamta", "sapna", "jyoti", "suman",
    "padma", "vidya", "radha", "uma", "sarita", "asha", "usha", "kalpana",
    "shobha", "lata", "chitra", "kamala", "pushpa", "savita", "sudha", "mala",
    "aruna", "saroj", "indira", "parvati", "malini", "revathi", "bhavani",
    "devi", "gowri", "janaki", "kalyani", "meenakshi", "nirmala", "sarala",
    "vasanthi", "vijaya", "yamuna", "sumathi", "jayanthi", "lalitha", "rohini",
    "preeti", "shweta", "ankita", "pallavi", "shruti", "aishwarya", "bhavna",
    "manisha", "rashmi", "varsha", "alka", "komal", "tanvi", "ritika", "sakshi",
    "aarthi", "karthika", "nandhini", "vaishnavi", "harini", "sangeetha",
    "mythili", "bhuvana", "abinaya", "dhivya", "gayathri", "keerthana",
    "mathangi", "oviya", "priyanka", "ramya", "swetha", "thenmozhi", "vani",
    "amita", "garima", "heena", "ila", "juhi", "kiran", "laxmi", "madhu",
    "namita", "omana", "payal", "rachana", "sonal", "tara", "urmila", "vinita"
}

def detect_gender_from_name(name: str) -> str:
    """Detect gender from borrower name using common Indian name patterns.
    Returns 'female' or 'male' (defaults to male if uncertain)."""
    if not name:
        return "male"
    
    # Extract first name
    first_name = name.strip().split()[0].lower()
    
    # Check against known female names
    if first_name in _FEMALE_NAMES:
        return "female"
    
    # Heuristic: many Indian female names end in 'a', 'i', or 'i'
    # But this is unreliable, so we default to male for safety
    return "male"

def calculate_follow_up_schedule(category):
    """
    Calculate follow-up dates based on category (Skipping Weekends):
    - Consistent: 1 call next week (business day)
    - Inconsistent: 3 calls (next 3 business days)
    - Overdue: Daily (next 7 business days)
    """
    from datetime import timedelta
    today = datetime.now()
    dates = []
    
    category = (category or "").lower()
    
    if "inconsistent" in category:
        required_dates = 3
        desc = "3 calls/week"
    elif "overdue" in category:
        required_dates = 7
        desc = "Daily (Business Days)"
    else:
        # Consistent: Just 1 call approximately a week later
        required_dates = 1
        # Start looking from 7 days ahead
        today = today + timedelta(days=6) 
        desc = "1 call/week"
        
    current_date = today
    count = 0
    
    while count < required_dates:
        # Move to next day
        current_date += timedelta(days=1)
        
        # Check if Sat (5) or Sun (6)
        if current_date.weekday() >= 5:
            continue
            
        dates.append(current_date.strftime("%Y-%m-%d"))
        count += 1
        
    return ", ".join(dates), desc

def determine_report_outcomes(intent, payment_date, category, borrower_name="Borrower", borrower_id="", is_mid_call=False):
    """
    Centralized logic to determine:
    - payment_confirmation
    - follow_up_date
    - call_frequency
    - require_manual_process
    - email_to_manager_preview
    - next_step_summary
    """
    from datetime import datetime, timedelta
    
    intent = (intent or "No Response").strip()
    category = (category or "Consistent").strip()
    
    next_step_summary = ""
    email_draft = None
    require_manual_process = False
    payment_confirmation = intent
    
    # 1. Handle Dates & Freq
    if is_mid_call:
        # Re-trigger Next Day
        today = datetime.now()
        next_day = today + timedelta(days=1)
        if next_day.weekday() >= 5: # Skip to Monday
            next_day += timedelta(days=(7 - next_day.weekday()))
        follow_up_date = next_day.strftime("%Y-%m-%d")
        call_frequency = "1 call (Retry)"
        next_step_summary = "The borrower hung up mid-sentence. System scheduled a follow-up retry for the next business day."
    elif payment_date and payment_date.lower() != "null":
        payment_confirmation = payment_date
        follow_up_date = payment_date
        call_frequency = "1 call (Verify)"
    else:
        follow_up_date, call_frequency = calculate_follow_up_schedule(category)

    # 2. Logic for Manual Process & Email Previews
    escalation_intents = ["Paid", "Dispute", "No Response", "Abusive Language", "Threatening Language", "Stop Calling"]
    
    if intent in escalation_intents:
        require_manual_process = True
        
        if intent == "Paid":
            next_step_summary = f"Borrower {borrower_name} claims payment made. Please verify."
            subject = f"Payment Verification Required: {borrower_name}"
            body = f"Hi Area Manager,\n\nBorrower {borrower_name} ({borrower_id}) claims they have already paid. Please verify the transaction.\n\nBest regards,\nAI System"
        elif intent == "Dispute":
            next_step_summary = "Borrower is disputing the loan payment. Escalating for manual investigation."
            subject = f"Payment Dispute: {borrower_name}"
            body = f"Hi Area Manager,\n\nBorrower {borrower_name} ({borrower_id}) is disputing the loan amount/terms. Manual investigation required.\n\nBest regards,\nAI System"
        elif intent == "No Response":
            next_step_summary = "No clear response from borrower. Escalating for manual follow-up."
            subject = f"No Response Escalation: {borrower_name}"
            body = f"Hi Area Manager,\n\nWe could not get a clear response from {borrower_name} ({borrower_id}). Please follow up manually.\n\nBest regards,\nAI System"
        elif intent == "Abusive Language":
            next_step_summary = "Borrower used abusive language. Escalating for manual process."
            subject = f"Alert: Abusive Language - {borrower_name}"
            body = f"Hi Area Manager,\n\nBorrower {borrower_name} ({borrower_id}) was abusive during the call. Initiating manual handling.\n\nBest regards,\nAI System"
        elif intent == "Threatening Language":
            next_step_summary = "Borrower used threatening language. Escalating for manual process."
            subject = f"Security Alert: {borrower_name}"
            body = f"Hi Area Manager,\n\nBorrower {borrower_name} ({borrower_id}) was threatening. Please handle this case with priority.\n\nBest regards,\nAI System"
        elif intent == "Stop Calling":
            next_step_summary = "Borrower requested to stop calls. Escalating for manual process."
            subject = f"DNC Request: {borrower_name}"
            body = f"Hi Area Manager,\n\nBorrower {borrower_name} ({borrower_id}) requested to stop calling. Please update legal status.\n\nBest regards,\nAI System"
        
        email_draft = {"to": "Area Manager", "subject": subject, "body": body}

    elif intent == "Will Pay" or intent == "Needs Extension":
        require_manual_process = False
        email_draft = None
        if payment_date:
            next_step_summary = f"Borrower committed to pay/extend until {payment_date}."
        else:
            next_step_summary = f"Borrower committed to {intent}. Follow-up scheduled."

    return {
        "payment_confirmation": payment_confirmation,
        "follow_up_date": follow_up_date,
        "call_frequency": call_frequency,
        "require_manual_process": require_manual_process,
        "email_to_manager_preview": email_draft,
        "next_step_summary": next_step_summary
    }

def generate_jwt_token():
    """Generate JWT token for Vonage API"""
    try:
        with open(settings.VONAGE_PRIVATE_KEY_PATH, 'rb') as key_file:
            private_key = key_file.read()
        
        payload = {
            'application_id': settings.VONAGE_APPLICATION_ID,
            'iat': int(time.time()),
            'exp': int(time.time()) + 3600,
            'jti': str(uuid.uuid4())
        }
        
        return jwt.encode(payload, private_key, algorithm='RS256')
    except Exception as e:
        print(f"[JWT] Error: {e}")
        return None


# ============================================================
# GEMINI AI ANALYSIS
# ============================================================

async def analyze_conversation_with_gemini(conversation):
    """
    COMMENTED OUT GEMINI: FORCING GROQ FOR NOW
    """
    print("[AI ANALYSIS] üîÑ Forcing Groq fallback as requested...")
    return await analyze_conversation_with_groq(conversation)

    # if not gemini_client:
    #     print("[GEMINI] ‚ö†Ô∏è  Gemini client not available, skipping analysis")
    #     return {
    #         "summary": "AI analysis not available - Gemini API not configured",
    #         "sentiment": "Neutral",
    #         "sentiment_reasoning": "Analysis skipped",
    #         "intent": "No Response",
    #         "intent_reasoning": "Analysis skipped",
    #         "payment_date": None
    #     }
    
    # # Prepare conversation text
    # conversation_text = "\n".join([
    #     f"{entry['speaker']}: {entry['text']}" 
    #     for entry in conversation
    # ])
    # 
    # prompt = f"""You are an AI analyst reviewing a phone conversation between a collection agent (AI) and a borrower (User).
    # 
    # Analyze this conversation and provide:
    # 
    # 1. **SUMMARY**: A concise 2-3 sentence summary of what was discussed.
    # 
    # 2. **SENTIMENT**: Classify as Positive, Neutral, or Negative.
    # 
    # 3. **INTENT**: Classify as one of the following:
    #    - **Paid**, **Will Pay**, **Needs Extension**, **Dispute**, **No Response**, **Abusive Language**, **Threatening Language**, **Stop Calling**.
    # 
    # 4. **MID_CALL**: Boolean (true/false). Set to true ONLY if the conversation ends abruptly or the borrower hangs up mid-sentence.
    # 
    # CONVERSATION:
    # {conversation_text}
    # 
    # Respond in JSON format only with these exact keys:
    # {{
    #     "summary": "...",
    #     "sentiment": "...",
    #     "sentiment_reasoning": "...",
    #     "intent": "...",
    #     "intent_reasoning": "...",
    #     "payment_date": "YYYY-MM-DD or null",
    #     "extension_date": "YYYY-MM-DD or null",
    #     "mid_call": true/false
    # }}"""
    # 
    # 
    # # Add retry logic for 429 Resource Exhausted
    # max_retries = 5
    # base_delay = 3
    # 
    # for attempt in range(max_retries):
    #     try:
    #         print(f"\n[GEMINI] ü§ñ Starting AI analysis (Attempt {attempt+1}/{max_retries})...")
    #         
    #         # Use async version of generate_content
    #         response = await gemini_client.aio.models.generate_content(
    #             model='gemini-2.0-flash',
    #             contents=prompt
    #         )
    #         
    #         response_text = response.text.strip()
    #         
    #         # Clean JSON
    #         if "```json" in response_text:
    #             response_text = response_text.split("```json")[1].split("```")[0].strip()
    #         elif "```" in response_text:
    #             response_text = response_text.split("```")[1].split("```")[0].strip()
    #         
    #         analysis = json.loads(response_text)
    #         print(f"[GEMINI] ‚úÖ Analysis completed successfully")
    #         return analysis
    # 
    #     except Exception as e:
    #         error_str = str(e).lower()
    #         if "429" in error_str or "resource_exhausted" in error_str:
    #             if attempt < max_retries - 1:
    #                 # Exponential backoff with random jitter to avoid thundering herd
    #                 delay = (base_delay * (2 ** attempt)) + random.uniform(0, 5)
    #                 print(f"[GEMINI] ‚è≥ Rate limit hit. Retrying in {delay:.1f}s...")
    #                 await asyncio.sleep(delay)
    #                 continue
    #             else:
    #                 print(f"[GEMINI] üö® Rate limit exhausted. Falling back to Groq...")
    #                 fallback = await analyze_conversation_with_groq(conversation)
    #                 if fallback: return fallback
    #         
    #         print(f"[GEMINI] ‚ùå Analysis error: {e}")
    #         
    #         if attempt < max_retries - 1:
    #             await asyncio.sleep(2)
    #             continue
    #         
    #         # Check if it's a 429 error and try fallback
    #         if "429" in str(e) or "RESOURCE_EXHAUSTED" in str(e):
    #             print(f"[GEMINI] üö® Rate limit hit. Attempting fallback to Groq...")
    #             fallback_analysis = await analyze_conversation_with_groq(conversation)
    #             if fallback_analysis:
    #                 return fallback_analysis
    #         
    #         return {
    #             "summary": "Unable to analyze conversation",
    #             "sentiment": "Neutral",
    #             "intent": "No Response"
    #         }
    # 
    # return {"summary": "Analysis failed", "sentiment": "Neutral", "intent": "No Response"}


async def analyze_conversation_with_groq(conversation):
    """
    Fallback analysis using Groq AI (Llama 3) when Gemini is unavailable or rate-limited.
    """
    
    if not groq_client:
        print("[GROQ] ‚ö†Ô∏è  Groq client not available, skipping fallback analysis")
        return None
    
    # Prepare conversation text
    conversation_text = "\n".join([
        f"{entry['speaker']}: {entry['text']}" 
        for entry in conversation
    ])
    
    today_date = datetime.now().strftime("%Y-%m-%d (%A)")
    
    prompt = f"""You are an AI analyst reviewing a phone conversation between a collection agent (AI) and a borrower (User).
    
    Current Date: {today_date}

Analyze this conversation and provide:
1. SUMMARY: A concise 2-3 sentence summary.
2. SENTIMENT: Positive, Neutral, or Negative.
3. INTENT: Paid, Will Pay, Needs Extension, Dispute, No Response, Abusive Language, Threatening Language, or Stop Calling.
4. PAYMENT_DATE: Extract EXACT date if mentioned (YYYY-MM-DD). handling "tomorrow", "next week", etc. relative to {today_date}. If no date, return null.
5. MID_CALL: Boolean (true/false). Set to true ONLY if the conversation ends abruptly or the borrower hangs up mid-sentence without a professional closing.

CONVERSATION:
{conversation_text}

Respond in JSON format only with these exact keys:
{{
    "summary": "...",
    "sentiment": "...",
    "intent": "...",
    "payment_date": "YYYY-MM-DD or null",
    "mid_call": true/false
}}"""

    
    try:
        print(f"\n[GROQ] ü§ñ Starting fallback AI analysis...")
        
        response = await groq_client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {"role": "system", "content": "You are a helpful assistant that responds in JSON format."},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"}
        )
        
        response_text = response.choices[0].message.content.strip()
        analysis = json.loads(response_text)
        print(f"[GROQ] ‚úÖ Analysis completed successfully via fallback")
        return analysis

    except Exception as e:
        print(f"[GROQ] ‚ùå Fallback analysis error: {e}")
        return None


# ============================================================
# SARVAM AI - STT/TTS
# ============================================================

def transcribe_sarvam(audio_data, language="en-IN", max_retries=2):
    """Transcribe audio using Sarvam AI STT"""
    if len(audio_data) < 2000: # Very short audio
        return None
    
    for attempt in range(max_retries):
        try:
            # Convert raw PCM audio to WAV format
            wav_buffer = BytesIO()
            with wave.open(wav_buffer, 'wb') as wav_file:
                wav_file.setnchannels(1)
                wav_file.setsampwidth(2)
                wav_file.setframerate(16000)
                wav_file.writeframes(audio_data)
            
            wav_buffer.seek(0)
            
            headers = {'api-subscription-key': settings.SARVAM_API_KEY}
            files = {'file': ('audio.wav', wav_buffer, 'audio/wav')}
            data = {'language_code': language, 'model': 'saarika:v2.5'}
            
            response = requests.post(
                'https://api.sarvam.ai/speech-to-text',
                headers=headers,
                files=files,
                data=data,
                timeout=10
            )
            
            if response.status_code == 200:
                transcript = response.json().get('transcript', '')
                if transcript: return transcript
            
        except Exception as e:
            print(f"[STT] ‚ùå Error: {e}")
            if attempt < max_retries - 1: time.sleep(0.5)
            
    return None


def synthesize_sarvam(text, language="en-IN", max_retries=2):
    """Convert text to speech using Sarvam AI TTS"""
    if not text: return None
        
    for attempt in range(max_retries):
        try:
            config = settings.LANGUAGE_CONFIG.get(language, {})
            speaker = config.get('speaker', 'manisha')
            
            headers = {
                'api-subscription-key': settings.SARVAM_API_KEY,
                'Content-Type': 'application/json'
            }
            
            payload = {
                'inputs': [text],
                'target_language_code': language,
                'speaker': speaker,
                'pitch': 0,
                'pace': 1.0,
                'loudness': 1.5,
                'speech_sample_rate': 16000,
                'model': 'bulbul:v2'
            }
            
            response = requests.post(
                'https://api.sarvam.ai/text-to-speech',
                headers=headers,
                json=payload,
                timeout=10
            )
            
            if response.status_code == 200:
                audio_base64 = response.json().get('audios', [None])[0]
                if audio_base64: return base64.b64decode(audio_base64)
                
        except Exception as e:
            print(f"[TTS] ‚ùå Error: {e}")
            if attempt < max_retries - 1: time.sleep(0.5)
            
    return None


# ============================================================
# LANGUAGE DETECTION
# ============================================================

def detect_language(text):
    """Simple language detection based on character sets"""
    text = text.strip()
    if re.search(r'[\u0900-\u097F]', text): return "hi-IN"
    if re.search(r'[\u0B80-\u0BFF]', text): return "ta-IN"
    return "en-IN"


# ============================================================
# AUDIO BUFFERING
# ============================================================

class AudioBuffer:
    """Buffer audio chunks and detect silence"""
    
    def __init__(self, silence_threshold=500, silence_duration=1.8):
        self.buffer = BytesIO()
        self.silence_threshold = silence_threshold
        self.silence_duration = silence_duration
        self.silence_start = None
        self.speech_detected = False
        self.min_speech_duration = 1.0
        
    def add_chunk(self, audio_chunk):
        """Add audio chunk and detect if ready to process"""
        self.buffer.write(audio_chunk)
        current_time = time.time()
        
        try:
            samples = struct.unpack(f'{len(audio_chunk)//2}h', audio_chunk)
            rms = sum(abs(s) for s in samples) / len(samples) if samples else 0
        except: rms = 0
        
        if rms >= self.silence_threshold:
            self.speech_detected = True
            self.silence_start = None
        
        if self.speech_detected and rms < self.silence_threshold:
            if self.silence_start is None:
                self.silence_start = current_time
            elif current_time - self.silence_start >= self.silence_duration:
                if self.buffer.tell() > (16000 * 2 * self.min_speech_duration):
                    return True
        
        if self.buffer.tell() > (16000 * 2 * 10): # 10s max
            if self.speech_detected: return True
        
        return False
    
    def get_audio(self):
        """Get buffered audio and reset"""
        audio_data = self.buffer.getvalue()
        self.buffer = BytesIO()
        self.silence_start = None
        self.speech_detected = False
        return audio_data


# ============================================================
# AI RESPONSE GENERATION
# ============================================================

def is_farewell_response(text, language="en-IN"):
    """Detect if the AI response is a FINAL farewell/closing statement.
    
    IMPORTANT: This must be VERY strict to avoid cutting calls mid-conversation.
    Only match when the response is clearly a goodbye (end of conversation),
    NOT when it merely contains words like 'thank you' or 'update records' 
    as part of an ongoing exchange.
    
    Strategy: Check that farewell phrases appear at the END of the text (last part),
    and that the text does NOT contain follow-up questions (like 'Do you have any questions?').
    """
    text_lower = text.lower().strip()
    
    # If the response contains a question, it's NOT a farewell ‚Äî the AI is still engaging
    question_indicators = ["?", "any questions", "anything else", "‡§ï‡•ã‡§à ‡§∏‡§µ‡§æ‡§≤", "‡§ï‡•Å‡§õ ‡§î‡§∞", "‡Æï‡Øá‡Æ≥‡Øç‡Æµ‡Æø", "‡Æµ‡Øá‡Æ±‡ØÅ ‡Æè‡Æ§‡Ææ‡Æµ‡Æ§‡ØÅ"]
    if any(q in text_lower for q in question_indicators):
        return False
    
    # Only check the TAIL of the response for farewell patterns
    # This avoids matching "thank you for telling us" at the start of a longer response
    tail = text_lower[-80:] if len(text_lower) > 80 else text_lower
    
    # ‚îÄ‚îÄ ENGLISH ‚îÄ‚îÄ
    farewell_patterns_en = [
        "have a good day",
        "have a nice day", 
        "goodbye",
        "good bye",
        "take care",
    ]
    
    # ‚îÄ‚îÄ HINDI ‚îÄ‚îÄ
    # "‡§¶‡§ø‡§® ‡§∂‡•Å‡§≠ ‡§π‡•ã" = have a good day (very specific)
    # "‡§Ö‡§≤‡§µ‡§ø‡§¶‡§æ" = goodbye  
    # "‡§ñ‡•ç‡§Ø‡§æ‡§≤ ‡§∞‡§ñ‡§ø‡§è" = take care
    farewell_patterns_hi = [
        "‡§¶‡§ø‡§® ‡§∂‡•Å‡§≠ ‡§π‡•ã",
        "‡§∂‡•Å‡§≠ ‡§¶‡§ø‡§®",
        "‡§Ö‡§≤‡§µ‡§ø‡§¶‡§æ",
        "‡§ñ‡•ç‡§Ø‡§æ‡§≤ ‡§∞‡§ñ‡§ø‡§è",
        "‡§ñ‡•ç‡§Ø‡§æ‡§≤ ‡§∞‡§ñ‡•á‡§Ç",
    ]
    
    # ‚îÄ‚îÄ TAMIL ‚îÄ‚îÄ
    # "‡Æ®‡Æ≤‡Øç‡Æ≤ ‡Æ®‡Ææ‡Æ≥‡Øç ‡Æµ‡Ææ‡Æ¥‡Øç‡Æ§‡Øç‡Æ§‡ØÅ‡Æï‡Æ≥‡Øç" = good day wishes (very specific)
    # "‡Æ™‡Øã‡ÆØ‡Øç ‡Æµ‡Æ∞‡ØÅ‡Æï‡Æø‡Æ±‡Øá‡Æ©‡Øç" = goodbye (I'll go and come)
    # "‡Æ®‡Æ≤‡ÆÆ‡Ææ‡Æï ‡Æá‡Æ∞‡ØÅ‡Æô‡Øç‡Æï‡Æ≥‡Øç" = be well / take care
    farewell_patterns_ta = [
        "‡Æ®‡Æ≤‡Øç‡Æ≤ ‡Æ®‡Ææ‡Æ≥‡Øç ‡Æµ‡Ææ‡Æ¥‡Øç‡Æ§‡Øç‡Æ§‡ØÅ‡Æï‡Æ≥‡Øç",
        "‡Æ®‡Æ≤‡Øç‡Æ≤ ‡Æ®‡Ææ‡Æ≥‡Øç",
        "‡Æ™‡Øã‡ÆØ‡Øç ‡Æµ‡Æ∞‡ØÅ‡Æï‡Æø‡Æ±‡Øá‡Æ©‡Øç",
        "‡Æ®‡Æ≤‡ÆÆ‡Ææ‡Æï ‡Æá‡Æ∞‡ØÅ‡Æô‡Øç‡Æï‡Æ≥‡Øç",
    ]
    
    if language == "hi-IN":
        return any(p in tail for p in farewell_patterns_hi)
    elif language == "ta-IN":
        return any(p in tail for p in farewell_patterns_ta)
    else:
        return any(p in tail for p in farewell_patterns_en)


def generate_ai_response(user_text, language="en-IN", context=None):
    """Generate AI response for real-time calls. Uses sync Groq (primary) or Gemini (fallback).
    Follows a structured conversation flow with gender-aware greetings.
    Responses are kept SHORT (1-2 sentences max) for natural phone conversation flow."""
    FALLBACKS = {
        "en-IN": "I understand. Could you tell me more about your payment status?",
        "hi-IN": "‡§Æ‡•à‡§Ç ‡§∏‡§Æ‡§ù ‡§∞‡§π‡•Ä ‡§π‡•Ç‡§Ç‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ö‡§™‡§®‡•á ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§ï‡•Ä ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§¨‡§§‡§æ‡§è‡§Ç?",
        "ta-IN": "‡Æ™‡ØÅ‡Æ∞‡Æø‡Æï‡Æø‡Æ±‡Æ§‡ØÅ. ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æï‡Æü‡Øç‡Æü‡Æ£ ‡Æ®‡Æø‡Æ≤‡Øà ‡Æ™‡Æ±‡Øç‡Æ±‡Æø ‡Æï‡ØÇ‡Æ±‡ØÅ‡Æô‡Øç‡Æï‡Æ≥‡Øç?"
    }
    
    conv_history = ""
    if context and "conversation" in context:
        conv_history = "\n".join([f"{e['speaker']}: {e['text']}" for e in context["conversation"][-6:]])
    
    # ‚îÄ‚îÄ BUILD BORROWER CONTEXT STRING ‚îÄ‚îÄ
    borrower_info_str = ""
    gender = "male"
    honorific_en = "sir"
    honorific_hi = "‡§∂‡•ç‡§∞‡•Ä‡§Æ‡§æ‡§®"
    honorific_ta = "‡Æê‡ÆØ‡Ææ"
    
    if context and "borrower_info" in context:
        bi = context["borrower_info"]
        b_name = bi.get('name', 'Unknown')
        gender = detect_gender_from_name(b_name)
        
        if gender == "female":
            honorific_en = "ma'am"
            honorific_hi = "‡§Æ‡•à‡§°‡§Æ"
            honorific_ta = "‡ÆÆ‡Øá‡Æü‡ÆÆ‡Øç"
        
        outstanding = bi.get('amount', 0)
        emi = bi.get('emi', 0)
        remaining_after_emi = outstanding - emi if outstanding and emi else 0
        
        gender_label = "sir" if gender == "male" else "ma'am"
        borrower_info_str = (
            f"\n\nBORROWER DATA (you already know this - use this naturally, NEVER ask for this info):\n"
            f"- Name: {b_name}\n"
            f"- Gender: {gender} (use {gender_label} accordingly)\n"
            f"- Outstanding Loan Amount: ‚Çπ{outstanding:,.2f}\n"
            f"- Monthly EMI: ‚Çπ{emi:,.2f}\n"
            f"- Remaining After This Month's Payment: ‚Çπ{remaining_after_emi:,.2f}\n"
            f"- Due Date: {bi.get('due_date', 'N/A')}\n"
            f"- Last Paid: {bi.get('last_paid', 'N/A')}\n"
            f"- Payment Category: {bi.get('payment_category', 'N/A')}\n"
            f"- Loan No: {bi.get('loan_no', 'N/A')}\n"
        )
    
    # System prompts with structured conversation flow
    sys_prompts = {
        "en-IN": (
            "You are Vidya, a polite loan collection assistant on a PHONE CALL. "
            "CRITICAL RULES:\n"
            "- Respond in English. Keep replies to 1-2 SHORT sentences (max 25 words total).\n"
            "- Never repeat what you already said. Be empathetic but direct.\n"
            f"- Address the borrower as '{honorific_en}' (based on their gender).\n"
            "- NEVER ask for information you already have (amount, name, dates).\n"
            "\nCONVERSATION FLOW TO FOLLOW:\n"
            "1. GREETING (already done): 'Hi Mr/Mrs [Name], hope you are doing well today. We are calling from the Loan sector, this is a general check-up call regarding the Loan amount that you have borrowed. Your due date is coming up soon [date]. Can you please let us know if you will be paying the balance amount before due date?'\n"
            "2. If borrower confirms they WILL PAY: 'Good to know {honorific}, we will update our records accordingly. Do you have any questions for us?'\n"
            "3. If borrower asks about loan amounts: 'Sure {honorific}, your current outstanding loan amount is [amount] and after payment of the due this month your loan amount would be [remaining].'\n"
            "4. When borrower says thank you or has no more questions: 'Thank you {honorific}, have a good day!'\n"
            "5. For any other scenario (dispute, extension, abusive etc.), handle professionally in 1 sentence.\n"
            + borrower_info_str
        ),
        "hi-IN": (
            "‡§Ü‡§™ ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ ‡§π‡•à‡§Ç, ‡§´‡•ã‡§® ‡§™‡§∞ ‡§≤‡•ã‡§® ‡§µ‡§∏‡•Ç‡§≤‡•Ä ‡§∏‡§π‡§æ‡§Ø‡§ï‡•§ "
            "‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§®‡§ø‡§Ø‡§Æ:\n"
            "- ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§Ç‡•§ 1-2 ‡§õ‡•ã‡§ü‡•á ‡§µ‡§æ‡§ï‡•ç‡§Ø‡•ã‡§Ç ‡§Æ‡•á‡§Ç (‡§Ö‡§ß‡§ø‡§ï‡§§‡§Æ 25 ‡§∂‡§¨‡•ç‡§¶) ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§Ç‡•§\n"
            "- ‡§ú‡•ã ‡§™‡§π‡§≤‡•á ‡§ï‡§π ‡§ö‡•Å‡§ï‡•Ä ‡§π‡•à‡§Ç ‡§µ‡•ã ‡§¶‡•ã‡§¨‡§æ‡§∞‡§æ ‡§® ‡§ï‡§π‡•á‡§Ç‡•§\n"
            f"- ‡§â‡§ß‡§æ‡§∞‡§ï‡§∞‡•ç‡§§‡§æ ‡§ï‡•ã '{honorific_hi}' ‡§ï‡§π‡•á‡§Ç (‡§â‡§®‡§ï‡•á ‡§≤‡§ø‡§Ç‡§ó ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞)‡•§\n"
            "- ‡§ú‡•ã ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§Ü‡§™‡§ï‡•á ‡§™‡§æ‡§∏ ‡§™‡§π‡§≤‡•á ‡§∏‡•á ‡§π‡•à (‡§∞‡§æ‡§∂‡§ø, ‡§®‡§æ‡§Æ, ‡§§‡§æ‡§∞‡•Ä‡§ñ) ‡§µ‡•ã ‡§ï‡§≠‡•Ä ‡§® ‡§™‡•Ç‡§õ‡•á‡§Ç‡•§\n"
            "\n‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§ï‡§æ ‡§ï‡•ç‡§∞‡§Æ:\n"
            "1. ‡§Ö‡§≠‡§ø‡§µ‡§æ‡§¶‡§® (‡§™‡§π‡§≤‡•á ‡§π‡•Ä ‡§π‡•ã ‡§ö‡•Å‡§ï‡§æ): '‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§∂‡•ç‡§∞‡•Ä/‡§∂‡•ç‡§∞‡•Ä‡§Æ‡§§‡•Ä [‡§®‡§æ‡§Æ] ‡§ú‡•Ä, ‡§Ü‡§∂‡§æ ‡§π‡•à ‡§Ü‡§™ ‡§Ö‡§ö‡•ç‡§õ‡•á ‡§π‡•à‡§Ç‡•§ ‡§π‡§Æ ‡§≤‡•ã‡§® ‡§∏‡•á‡§ï‡•ç‡§ü‡§∞ ‡§∏‡•á ‡§ï‡•â‡§≤ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç, ‡§Ø‡§π ‡§Ü‡§™‡§ï‡•á ‡§â‡§ß‡§æ‡§∞ ‡§≤‡§ø‡§è ‡§ó‡§è ‡§≤‡•ã‡§® ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§´‡•â‡§≤‡•ã-‡§Ö‡§™ ‡§ï‡•â‡§≤ ‡§π‡•à‡•§ ‡§Ü‡§™‡§ï‡•Ä due date ‡§ú‡§≤‡•ç‡§¶ ‡§Ü ‡§∞‡§π‡•Ä ‡§π‡•à [‡§§‡§æ‡§∞‡•Ä‡§ñ]‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ due date ‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§¨‡§ï‡§æ‡§Ø‡§æ ‡§∞‡§æ‡§∂‡§ø ‡§ï‡§æ ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§ï‡§∞ ‡§¶‡•á‡§Ç‡§ó‡•á?'\n"
            f"2. ‡§Ö‡§ó‡§∞ ‡§â‡§ß‡§æ‡§∞‡§ï‡§∞‡•ç‡§§‡§æ ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§ï‡•Ä ‡§™‡•Å‡§∑‡•ç‡§ü‡§ø ‡§ï‡§∞‡•á: '‡§Ø‡§π ‡§∏‡•Å‡§®‡§ï‡§∞ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§≤‡§ó‡§æ {honorific_hi}, ‡§π‡§Æ ‡§Ö‡§™‡§®‡•á ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§Ö‡§™‡§°‡•á‡§ü ‡§ï‡§∞ ‡§¶‡•á‡§Ç‡§ó‡•á‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™‡§ï‡§æ ‡§ï‡•ã‡§à ‡§∏‡§µ‡§æ‡§≤ ‡§π‡•à?'\n"
            f"3. ‡§Ö‡§ó‡§∞ ‡§≤‡•ã‡§® ‡§∞‡§æ‡§∂‡§ø ‡§™‡•Ç‡§õ‡•á‡§Ç: '‡§ú‡•Ä {honorific_hi}, ‡§Ü‡§™‡§ï‡•Ä ‡§µ‡§∞‡•ç‡§§‡§Æ‡§æ‡§® ‡§ï‡•Å‡§≤ ‡§¨‡§ï‡§æ‡§Ø‡§æ ‡§≤‡•ã‡§® ‡§∞‡§æ‡§∂‡§ø [‡§∞‡§æ‡§∂‡§ø] ‡§π‡•à ‡§î‡§∞ ‡§á‡§∏ ‡§Æ‡§π‡•Ä‡§®‡•á ‡§ï‡•á ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§Ü‡§™‡§ï‡•Ä ‡§¨‡§ï‡§æ‡§Ø‡§æ ‡§∞‡§æ‡§∂‡§ø [‡§∂‡•á‡§∑] ‡§π‡•ã‡§ó‡•Ä‡•§'\n"
            f"4. ‡§ú‡§¨ ‡§â‡§ß‡§æ‡§∞‡§ï‡§∞‡•ç‡§§‡§æ ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶ ‡§ï‡§π‡•á‡§Ç ‡§Ø‡§æ ‡§ï‡•ã‡§à ‡§∏‡§µ‡§æ‡§≤ ‡§® ‡§π‡•ã: '‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶ {honorific_hi}, ‡§Ü‡§™‡§ï‡§æ ‡§¶‡§ø‡§® ‡§∂‡•Å‡§≠ ‡§π‡•ã!'\n"
            "5. ‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§Ö‡§®‡•ç‡§Ø ‡§∏‡•ç‡§•‡§ø‡§§‡§ø (‡§µ‡§ø‡§µ‡§æ‡§¶, ‡§è‡§ï‡•ç‡§∏‡§ü‡•á‡§Ç‡§∂‡§®, ‡§Ö‡§≠‡§¶‡•ç‡§∞) ‡§ï‡•ã 1 ‡§µ‡§æ‡§ï‡•ç‡§Ø ‡§Æ‡•á‡§Ç ‡§™‡•á‡§∂‡•á‡§µ‡§∞ ‡§§‡§∞‡•Ä‡§ï‡•á ‡§∏‡•á ‡§∏‡§Ç‡§≠‡§æ‡§≤‡•á‡§Ç‡•§\n"
            + borrower_info_str
        ),
        "ta-IN": (
            "‡Æ®‡ØÄ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æµ‡Æø‡Æ§‡Øç‡ÆØ‡Ææ, ‡Æ§‡Øä‡Æ≤‡Øà‡Æ™‡Øá‡Æö‡Æø‡ÆØ‡Æø‡Æ≤‡Øç ‡Æï‡Æü‡Æ©‡Øç ‡Æµ‡Æö‡ØÇ‡Æ≤‡Øç ‡Æâ‡Æ§‡Æµ‡Æø‡ÆØ‡Ææ‡Æ≥‡Æ∞‡Øç. "
            "‡ÆÆ‡ØÅ‡Æï‡Øç‡Æï‡Æø‡ÆØ ‡Æµ‡Æø‡Æ§‡Æø‡Æï‡Æ≥‡Øç:\n"
            "- ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Æø‡Æ≤‡Øç ‡Æ™‡Æ§‡Æø‡Æ≤‡Æ≥‡Æø‡Æï‡Øç‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç. 1-2 ‡Æï‡ØÅ‡Æ±‡ØÅ‡Æï‡Æø‡ÆØ ‡Æµ‡Ææ‡Æï‡Øç‡Æï‡Æø‡ÆØ‡Æô‡Øç‡Æï‡Æ≥‡Æø‡Æ≤‡Øç (‡ÆÖ‡Æ§‡Æø‡Æï‡Æ™‡Æü‡Øç‡Æö‡ÆÆ‡Øç 25 ‡Æµ‡Ææ‡Æ∞‡Øç‡Æ§‡Øç‡Æ§‡Øà‡Æï‡Æ≥‡Øç) ‡Æ™‡Æ§‡Æø‡Æ≤‡Æ≥‡Æø‡Æï‡Øç‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç.\n"
            "- ‡Æè‡Æ±‡Øç‡Æï‡Æ©‡Æµ‡Øá ‡Æï‡ØÇ‡Æ±‡Æø‡ÆØ‡Æ§‡Øà ‡ÆÆ‡ØÄ‡Æ£‡Øç‡Æü‡ØÅ‡ÆÆ‡Øç ‡Æï‡ØÇ‡Æ±‡Ææ‡Æ§‡ØÄ‡Æ∞‡Øç‡Æï‡Æ≥‡Øç.\n"
            f"- ‡Æï‡Æü‡Æ©‡Øç ‡Æµ‡Ææ‡Æô‡Øç‡Æï‡Æø‡ÆØ‡Æµ‡Æ∞‡Øà '{honorific_ta}' ‡Æé‡Æ©‡Øç‡Æ±‡ØÅ ‡ÆÖ‡Æ¥‡Øà‡ÆØ‡ØÅ‡Æô‡Øç‡Æï‡Æ≥‡Øç (‡Æ™‡Ææ‡Æ≤‡Æø‡Æ©‡Æ§‡Øç‡Æ§‡Æø‡Æ©‡Øç ‡ÆÖ‡Æü‡Æø‡Æ™‡Øç‡Æ™‡Æü‡Øà‡ÆØ‡Æø‡Æ≤‡Øç).\n"
            "- ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Æø‡Æü‡ÆÆ‡Øç ‡Æè‡Æ±‡Øç‡Æï‡Æ©‡Æµ‡Øá ‡Æâ‡Æ≥‡Øç‡Æ≥ ‡Æ§‡Æï‡Æµ‡Æ≤‡Øç‡Æï‡Æ≥‡Øà (‡Æ§‡Øä‡Æï‡Øà, ‡Æ™‡ØÜ‡ÆØ‡Æ∞‡Øç, ‡Æ§‡Øá‡Æ§‡Æø‡Æï‡Æ≥‡Øç) ‡Æí‡Æ∞‡ØÅ‡Æ™‡Øã‡Æ§‡ØÅ‡ÆÆ‡Øç ‡Æï‡Øá‡Æü‡Øç‡Æï‡Ææ‡Æ§‡ØÄ‡Æ∞‡Øç‡Æï‡Æ≥‡Øç.\n"
            "\n‡Æâ‡Æ∞‡Øà‡ÆØ‡Ææ‡Æü‡Æ≤‡Øç ‡Æµ‡Æ∞‡Æø‡Æö‡Øà:\n"
            "1. ‡Æµ‡Ææ‡Æ¥‡Øç‡Æ§‡Øç‡Æ§‡ØÅ (‡Æè‡Æ±‡Øç‡Æï‡Æ©‡Æµ‡Øá ‡Æö‡ØÜ‡ÆØ‡Øç‡ÆØ‡Æ™‡Øç‡Æ™‡Æü‡Øç‡Æü‡Æ§‡ØÅ): '‡Æµ‡Æ£‡Æï‡Øç‡Æï‡ÆÆ‡Øç ‡Æ§‡Æø‡Æ∞‡ØÅ/‡Æ§‡Æø‡Æ∞‡ØÅ‡ÆÆ‡Æ§‡Æø [‡Æ™‡ØÜ‡ÆØ‡Æ∞‡Øç], ‡Æ®‡Æ≤‡ÆÆ‡Ææ‡Æï ‡Æá‡Æ∞‡ØÅ‡Æ™‡Øç‡Æ™‡ØÄ‡Æ∞‡Øç‡Æï‡Æ≥‡Øç ‡Æé‡Æ© ‡Æ®‡ÆÆ‡Øç‡Æ™‡ØÅ‡Æï‡Æø‡Æ±‡Øá‡Æ©‡Øç. ‡Æï‡Æü‡Æ©‡Øç ‡Æ™‡Æø‡Æ∞‡Æø‡Æµ‡Æø‡Æ≤‡Æø‡Æ∞‡ØÅ‡Æ®‡Øç‡Æ§‡ØÅ ‡ÆÖ‡Æ¥‡Øà‡Æï‡Øç‡Æï‡Æø‡Æ±‡Øã‡ÆÆ‡Øç, ‡Æ®‡ØÄ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æ™‡ØÜ‡Æ±‡Øç‡Æ± ‡Æï‡Æü‡Æ©‡Øç ‡Æ§‡Øä‡Æï‡Øà ‡Æï‡ØÅ‡Æ±‡Æø‡Æ§‡Øç‡Æ§ ‡Æµ‡Æ¥‡Æï‡Øç‡Æï‡ÆÆ‡Ææ‡Æ© ‡Æ™‡Æø‡Æ©‡Øç‡Æ§‡Øä‡Æü‡Æ∞‡Øç ‡ÆÖ‡Æ¥‡Øà‡Æ™‡Øç‡Æ™‡ØÅ. ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æö‡ØÜ‡Æ≤‡ØÅ‡Æ§‡Øç‡Æ§ ‡Æµ‡Øá‡Æ£‡Øç‡Æü‡Æø‡ÆØ ‡Æ§‡Øá‡Æ§‡Æø ‡Æµ‡Æ∞‡Æµ‡Æø‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡Æø‡Æ±‡Æ§‡ØÅ [‡Æ§‡Øá‡Æ§‡Æø]. ‡Æ®‡Æø‡Æ≤‡ØÅ‡Æµ‡Øà‡Æ§‡Øç ‡Æ§‡Øä‡Æï‡Øà‡ÆØ‡Øà due date-‡Æï‡Øç‡Æï‡ØÅ ‡ÆÆ‡ØÅ‡Æ©‡Øç ‡Æö‡ØÜ‡Æ≤‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ‡Æµ‡ØÄ‡Æ∞‡Øç‡Æï‡Æ≥‡Ææ?'\n"
            f"2. ‡Æï‡Æü‡Æ©‡Øç ‡Æµ‡Ææ‡Æô‡Øç‡Æï‡Æø‡ÆØ‡Æµ‡Æ∞‡Øç ‡Æö‡ØÜ‡Æ≤‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ‡Æµ‡Æ§‡Ææ‡Æï ‡Æâ‡Æ±‡ØÅ‡Æ§‡Æø‡ÆØ‡Æ≥‡Æø‡Æ§‡Øç‡Æ§‡Ææ‡Æ≤‡Øç: '‡Æ®‡Æ≤‡Øç‡Æ≤‡Æ§‡ØÅ {honorific_ta}, ‡Æ®‡Ææ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æé‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æ™‡Æ§‡Æø‡Æµ‡ØÅ‡Æï‡Æ≥‡Øà ‡ÆÖ‡Æ§‡Æ±‡Øç‡Æï‡Øá‡Æ±‡Øç‡Æ™ ‡Æ™‡ØÅ‡Æ§‡ØÅ‡Æ™‡Øç‡Æ™‡Æø‡Æ™‡Øç‡Æ™‡Øã‡ÆÆ‡Øç. ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡ØÅ ‡Æè‡Æ§‡Ææ‡Æµ‡Æ§‡ØÅ ‡Æï‡Øá‡Æ≥‡Øç‡Æµ‡Æø‡Æï‡Æ≥‡Øç ‡Æâ‡Æ≥‡Øç‡Æ≥‡Æ§‡Ææ?'\n"
            f"3. ‡Æï‡Æü‡Æ©‡Øç ‡Æ§‡Øä‡Æï‡Øà ‡Æï‡ØÅ‡Æ±‡Æø‡Æ§‡Øç‡Æ§‡ØÅ ‡Æï‡Øá‡Æü‡Øç‡Æü‡Ææ‡Æ≤‡Øç: '‡Æ®‡Æø‡Æö‡Øç‡Æö‡ÆØ‡ÆÆ‡Ææ‡Æï {honorific_ta}, ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æ§‡Æ±‡Øç‡Æ™‡Øã‡Æ§‡Øà‡ÆØ ‡Æï‡Æü‡Æ©‡Øç ‡Æ®‡Æø‡Æ≤‡ØÅ‡Æµ‡Øà [‡Æ§‡Øä‡Æï‡Øà] ‡ÆÆ‡Æ±‡Øç‡Æ±‡ØÅ‡ÆÆ‡Øç ‡Æá‡Æ®‡Øç‡Æ§ ‡ÆÆ‡Ææ‡Æ§ ‡Æï‡Æü‡Øç‡Æü‡Æ£‡Æ§‡Øç‡Æ§‡Æø‡Æ±‡Øç‡Æï‡ØÅ‡Æ™‡Øç ‡Æ™‡Æø‡Æ±‡Æï‡ØÅ ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æï‡Æü‡Æ©‡Øç ‡Æ®‡Æø‡Æ≤‡ØÅ‡Æµ‡Øà [‡ÆÆ‡ØÄ‡Æ§‡ÆÆ‡ØÅ‡Æ≥‡Øç‡Æ≥] ‡ÆÜ‡Æï‡ØÅ‡ÆÆ‡Øç.'\n"
            f"4. ‡Æ®‡Æ©‡Øç‡Æ±‡Æø ‡Æö‡Øä‡Æ≤‡Øç‡Æ≤‡ØÅ‡ÆÆ‡Øç‡Æ™‡Øã‡Æ§‡ØÅ ‡ÆÖ‡Æ≤‡Øç‡Æ≤‡Æ§‡ØÅ ‡Æï‡Øá‡Æ≥‡Øç‡Æµ‡Æø‡Æï‡Æ≥‡Øç ‡Æá‡Æ≤‡Øç‡Æ≤‡Øà ‡Æé‡Æ©‡Øç‡Æ±‡Ææ‡Æ≤‡Øç: '‡Æ®‡Æ©‡Øç‡Æ±‡Æø {honorific_ta}, ‡Æ®‡Æ≤‡Øç‡Æ≤ ‡Æ®‡Ææ‡Æ≥‡Øç ‡Æµ‡Ææ‡Æ¥‡Øç‡Æ§‡Øç‡Æ§‡ØÅ‡Æï‡Æ≥‡Øç!'\n"
            "5. ‡Æ™‡Æø‡Æ± ‡Æö‡ØÇ‡Æ¥‡Øç‡Æ®‡Æø‡Æ≤‡Øà‡Æï‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡ØÅ (‡Æö‡Æ∞‡Øç‡Æö‡Øç‡Æö‡Øà, ‡Æ®‡ØÄ‡Æü‡Øç‡Æü‡Æø‡Æ™‡Øç‡Æ™‡ØÅ, ‡ÆÖ‡Æµ‡ÆÆ‡Æ∞‡Æø‡ÆØ‡Ææ‡Æ§‡Øà) 1 ‡Æµ‡Ææ‡Æï‡Øç‡Æï‡Æø‡ÆØ‡Æ§‡Øç‡Æ§‡Æø‡Æ≤‡Øç ‡Æ§‡Øä‡Æ¥‡Æø‡Æ≤‡Øç‡ÆÆ‡ØÅ‡Æ±‡Øà‡ÆØ‡Ææ‡Æï ‡Æï‡Øà‡ÆØ‡Ææ‡Æ≥‡ØÅ‡Æô‡Øç‡Æï‡Æ≥‡Øç.\n"
            + borrower_info_str
        )
    }
    
    system_prompt = sys_prompts.get(language, sys_prompts['en-IN'])
    user_message = f"Conversation so far:\n{conv_history}\n\nUser just said: {user_text}\n\nRespond with 1-2 short sentences following the conversation flow above."
    
    # PRIMARY: Use sync Groq client (fast, no async issues in Flask)
    if sync_groq_client:
        try:
            response = sync_groq_client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                max_tokens=100,
                temperature=0.7
            )
            result = response.choices[0].message.content.strip()
            print(f"[GROQ] ‚úÖ Real-time response generated ({len(result)} chars)")
            return result
        except Exception as e:
            print(f"[GROQ] ‚ùå Sync response error: {e}")
    
    # FALLBACK: Use Gemini
    if gemini_client:
        try:
            prompt = f"{system_prompt}\n\n{user_message}\n\nAI (1-2 short sentences only):"
            response = gemini_client.models.generate_content(
                model='gemini-2.0-flash',
                contents=prompt,
                config=types.GenerateContentConfig(temperature=0.7, max_output_tokens=100)
            )
            return response.text.strip()
        except Exception as e:
            print(f"[GEMINI] ‚ùå Fallback response error: {e}")
    
    return FALLBACKS.get(language, FALLBACKS["en-IN"])


# ============================================================
# CONVERSATION HANDLER
# ============================================================

class ConversationHandler:
    """Manages conversation state and transcript with USER ISOLATION"""
    
    def __init__(self, call_uuid, user_id=None, preferred_language="en-IN", borrower_id=None):
        self.call_uuid = call_uuid
        self.user_id = user_id
        self.borrower_id = borrower_id
        self.conversation = []
        self.context = {}
        self.is_active = True
        self.start_time = datetime.now()
        self.preferred_language = preferred_language
        self.current_language = preferred_language
        self.language_history = []
        
    def add_entry(self, speaker, text):
        entry = {
            "speaker": speaker,
            "text": text,
            "timestamp": datetime.now().isoformat(),
            "language": self.current_language
        }
        self.conversation.append(entry)
        self.context["conversation"] = self.conversation
        print(f"[CONV] [{self.user_id}] [{speaker}] {text}")
    
    def update_language(self, detected_language):
        if detected_language != self.current_language:
            self.language_history.append({
                "from": self.current_language,
                "to": detected_language,
                "timestamp": datetime.now().isoformat()
            })
            self.current_language = detected_language
    
    async def save_transcript(self):
        """Save transcript using standalone model functions with User Isolation"""
        duration = (datetime.now() - self.start_time).total_seconds()
        
        # Use Groq for analysis
        ai_analysis = await analyze_conversation_with_groq(self.conversation) if len(self.conversation) > 1 else {
            "summary": "No meaningful conversation detected",
            "sentiment": "No Response",
            "intent": "No Response",
            "payment_date": None
        }
        
        transcript_data = {
            "call_uuid": self.call_uuid,
            "user_id": self.user_id,
            "start_time": self.start_time.isoformat(),
            "end_time": datetime.now().isoformat(),
            "duration_seconds": round(duration, 2),
            "preferred_language": self.preferred_language,
            "final_language": self.current_language,
            "conversation": self.conversation,
            "ai_analysis": ai_analysis
        }
        
        # Save to MongoDB using isolated model functions
        try:
            # Note: create_call_session is async, and we are in an async function
            await create_call_session(self.user_id, transcript_data)
            
            # Update Borrower if ID exists
            if self.borrower_id and self.user_id:
                # 1. Get current borrower to check category
                from app.table_models.borrowers_table import get_borrower_by_no
                borrower = await get_borrower_by_no(self.user_id, self.borrower_id)
                category = borrower.get("Payment_Category", "Consistent") if borrower else "Consistent"
                
                # 2. Determine Logic
                payment_date = ai_analysis.get("payment_date")
                intent = ai_analysis.get("intent", "No Response")
                is_mid_call = ai_analysis.get("mid_call", False)
                borrower_name = borrower.get("BORROWER", "Borrower")
                
                outcomes = determine_report_outcomes(
                    intent, 
                    payment_date, 
                    category, 
                    borrower_name=borrower_name, 
                    borrower_id=self.borrower_id,
                    is_mid_call=is_mid_call
                )
                
                update_payload = {
                    "call_completed": True,
                    "call_in_progress": False,
                    "transcript": self.conversation,
                    "ai_summary": outcomes["next_step_summary"] or ai_analysis.get('summary', 'Done'),
                    "payment_confirmation": outcomes["payment_confirmation"],
                    "follow_up_date": outcomes["follow_up_date"],
                    "call_frequency": outcomes["call_frequency"],
                    "require_manual_process": outcomes["require_manual_process"],
                    "email_to_manager_preview": outcomes["email_to_manager_preview"]
                }
                
                print(f"[DB] üíæ Saving Borrower Update: {update_payload}")
                await update_borrower(self.user_id, self.borrower_id, update_payload)
        except Exception as e:
            print(f"[DB] ‚ùå Isolated Save Error: {e}")
        
        return f"transcript_{self.call_uuid}.json"


# ============================================================
# CALL MANAGEMENT
# ============================================================

def make_outbound_call(user_id, to_number, language="en-IN", borrower_id=None):
    """Trigger an isolated outbound call passing user_id to webhooks"""
    if not voice:
        return {"success": False, "error": "Vonage client not initialized"}
    
    # Clean the number: remove +, spaces, dashes
    to_number = to_number.strip().replace(' ', '').replace('-', '')
    if to_number.startswith('+'): to_number = to_number[1:]
    
    # Auto-prepend 91 (India) country code for 10-digit Indian mobile numbers
    # Indian mobile numbers start with 6, 7, 8, or 9
    if len(to_number) == 10 and to_number[0] in '6789':
        to_number = '91' + to_number
        print(f"[VONAGE] üì± Auto-prepended country code: 91 ‚Üí {to_number}")
    
    try:
        # Include user_id in answer URL for isolation in the webhook handler
        answer_url = f'{settings.BASE_URL}/webhooks/answer?preferred_language={language}&user_id={user_id}'
        if borrower_id:
            answer_url += f'&borrower_id={borrower_id}'
        
        print(f"\n[VONAGE] üìû Attempting outbound call to {to_number}...", flush=True)
        print(f"  From: {settings.VONAGE_FROM_NUMBER}", flush=True)
        print(f"  Answer URL: {answer_url}", flush=True)
        
        if not settings.VONAGE_FROM_NUMBER:
            print("[VONAGE] üö® ERROR: VONAGE_FROM_NUMBER is not set in environment variables!", flush=True)
            return {"success": False, "error": "VONAGE_FROM_NUMBER is not configured"}

        response = voice.create_call({
            'to': [{'type': 'phone', 'number': to_number}],
            'from_': {'type': 'phone', 'number': settings.VONAGE_FROM_NUMBER},
            'answer_url': [answer_url],
            'event_url': [f'{settings.BASE_URL}/webhooks/event']
        })
        
        print(f"[VONAGE] ‚úÖ Call successfully initiated! UUID: {response.uuid}", flush=True)
        
        return {
            "success": True,
            "call_uuid": response.uuid,
            "status": "initiated",
            "user_id": user_id
        }
        
    except Exception as e:
        error_msg = str(e)
        print(f"[VONAGE] ‚ùå Outbound Error Detail: {error_msg}", flush=True)
        # Check for common Vonage errors
        if "401" in error_msg:
            print("[VONAGE] üö® Authentication Failed: Check your API Key, Secret, and Application ID.", flush=True)
        elif "429" in error_msg:
            print("[VONAGE] üö® Rate Limit: Too many requests.", flush=True)
        return {"success": False, "error": error_msg}

def get_call_data_store():
    return call_data